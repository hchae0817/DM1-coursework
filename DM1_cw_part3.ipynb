{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91d996b0",
   "metadata": {},
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb7135a",
   "metadata": {},
   "source": [
    "## [13 points] \n",
    "\n",
    "### Compute the possible sentiments that a tweet may have, the second most popular sentiment in the tweets, and the date with the greatest number of extremely positive tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94506116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3: Mining text data.\n",
    "\n",
    "# Return a pandas dataframe containing the data set.\n",
    "# Specify a 'latin-1' encoding when reading the data.\n",
    "# data_file will be populated with the string 'wholesale_customers.csv'.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def read_csv_3(data_file):\n",
    "    data_file = pd.read_csv(data_file, encoding ='latin1')\n",
    "    return data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fc0ad86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41152</th>\n",
       "      <td>44951</td>\n",
       "      <td>89903</td>\n",
       "      <td>Wellington City, New Zealand</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>Airline pilots offering to stock supermarket s...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41153</th>\n",
       "      <td>44952</td>\n",
       "      <td>89904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>Response to complaint not provided citing COVI...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41154</th>\n",
       "      <td>44953</td>\n",
       "      <td>89905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>You know itÂs getting tough when @KameronWild...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41155</th>\n",
       "      <td>44954</td>\n",
       "      <td>89906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>Is it wrong that the smell of hand sanitizer i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41156</th>\n",
       "      <td>44955</td>\n",
       "      <td>89907</td>\n",
       "      <td>i love you so much || he/him</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>@TartiiCat Well new/used Rift S are going for ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41157 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       UserName  ScreenName                      Location     TweetAt  \\\n",
       "0          3799       48751                        London  16-03-2020   \n",
       "1          3800       48752                            UK  16-03-2020   \n",
       "2          3801       48753                     Vagabonds  16-03-2020   \n",
       "3          3802       48754                           NaN  16-03-2020   \n",
       "4          3803       48755                           NaN  16-03-2020   \n",
       "...         ...         ...                           ...         ...   \n",
       "41152     44951       89903  Wellington City, New Zealand  14-04-2020   \n",
       "41153     44952       89904                           NaN  14-04-2020   \n",
       "41154     44953       89905                           NaN  14-04-2020   \n",
       "41155     44954       89906                           NaN  14-04-2020   \n",
       "41156     44955       89907  i love you so much || he/him  14-04-2020   \n",
       "\n",
       "                                           OriginalTweet           Sentiment  \n",
       "0      @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1      advice Talk to your neighbours family to excha...            Positive  \n",
       "2      Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3      My food stock is not the only one which is emp...            Positive  \n",
       "4      Me, ready to go at supermarket during the #COV...  Extremely Negative  \n",
       "...                                                  ...                 ...  \n",
       "41152  Airline pilots offering to stock supermarket s...             Neutral  \n",
       "41153  Response to complaint not provided citing COVI...  Extremely Negative  \n",
       "41154  You know itÂs getting tough when @KameronWild...            Positive  \n",
       "41155  Is it wrong that the smell of hand sanitizer i...             Neutral  \n",
       "41156  @TartiiCat Well new/used Rift S are going for ...            Negative  \n",
       "\n",
       "[41157 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_csv_3('coronavirus_tweets.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc9f96f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a list with the possible sentiments that a tweet might have.\n",
    "def get_sentiments(df):\n",
    "    arr = df[\"Sentiment\"].to_numpy()\n",
    "    unique_arr = np.unique(arr)\n",
    "    return list(unique_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ed2036e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Extremely Negative', 'Extremely Positive', 'Negative', 'Neutral', 'Positive']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiments(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d566458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a string containing the second most popular sentiment among the tweets.\n",
    "def second_most_popular_sentiment(df):\n",
    "    most = df['Sentiment'].value_counts()[1:2]\n",
    "    return (most.index)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e415dab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_most_popular_sentiment(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71289dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the date (string as it appears in the data) with the greatest number of extremely positive tweets.\n",
    "def date_most_popular_tweets(df):\n",
    "    dates = df.loc[df['Sentiment'] == 'Extremely Positive']\n",
    "    dates_list = dates[\"TweetAt\"].value_counts()\n",
    "    return dates_list.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d74410af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'25-03-2020'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_most_popular_tweets(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7d9e69",
   "metadata": {},
   "source": [
    "### Next, convert the messages to lower case, replace non-alphabetical characters with whitespaces and ensure that the words of a message are separated by a single whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04910a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the dataframe df by converting all tweets to lower case. \n",
    "def lower_case(df):\n",
    "    df['OriginalTweet'] = df['OriginalTweet'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9057a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@menyrbie @phil_gahan @chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>coronavirus australia: woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>my food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>me, ready to go at supermarket during the #cov...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41152</th>\n",
       "      <td>44951</td>\n",
       "      <td>89903</td>\n",
       "      <td>Wellington City, New Zealand</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>airline pilots offering to stock supermarket s...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41153</th>\n",
       "      <td>44952</td>\n",
       "      <td>89904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>response to complaint not provided citing covi...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41154</th>\n",
       "      <td>44953</td>\n",
       "      <td>89905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>you know itâs getting tough when @kameronwild...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41155</th>\n",
       "      <td>44954</td>\n",
       "      <td>89906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>is it wrong that the smell of hand sanitizer i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41156</th>\n",
       "      <td>44955</td>\n",
       "      <td>89907</td>\n",
       "      <td>i love you so much || he/him</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>@tartiicat well new/used rift s are going for ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41157 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       UserName  ScreenName                      Location     TweetAt  \\\n",
       "0          3799       48751                        London  16-03-2020   \n",
       "1          3800       48752                            UK  16-03-2020   \n",
       "2          3801       48753                     Vagabonds  16-03-2020   \n",
       "3          3802       48754                           NaN  16-03-2020   \n",
       "4          3803       48755                           NaN  16-03-2020   \n",
       "...         ...         ...                           ...         ...   \n",
       "41152     44951       89903  Wellington City, New Zealand  14-04-2020   \n",
       "41153     44952       89904                           NaN  14-04-2020   \n",
       "41154     44953       89905                           NaN  14-04-2020   \n",
       "41155     44954       89906                           NaN  14-04-2020   \n",
       "41156     44955       89907  i love you so much || he/him  14-04-2020   \n",
       "\n",
       "                                           OriginalTweet           Sentiment  \n",
       "0      @menyrbie @phil_gahan @chrisitv https://t.co/i...             Neutral  \n",
       "1      advice talk to your neighbours family to excha...            Positive  \n",
       "2      coronavirus australia: woolworths to give elde...            Positive  \n",
       "3      my food stock is not the only one which is emp...            Positive  \n",
       "4      me, ready to go at supermarket during the #cov...  Extremely Negative  \n",
       "...                                                  ...                 ...  \n",
       "41152  airline pilots offering to stock supermarket s...             Neutral  \n",
       "41153  response to complaint not provided citing covi...  Extremely Negative  \n",
       "41154  you know itâs getting tough when @kameronwild...            Positive  \n",
       "41155  is it wrong that the smell of hand sanitizer i...             Neutral  \n",
       "41156  @tartiicat well new/used rift s are going for ...            Negative  \n",
       "\n",
       "[41157 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_case(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64b0220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the dataframe df by replacing each characters which is not alphabetic or whitespace with a whitespace.\n",
    "def remove_non_alphabetic_chars(df):\n",
    "    df['OriginalTweet'] = df['OriginalTweet'].str.replace('[^a-zA_Z]', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58505960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>menyrbie  phil_gahan  chrisitv https   t co i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>coronavirus australia  woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>my food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>me  ready to go at supermarket during the  cov...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41152</th>\n",
       "      <td>44951</td>\n",
       "      <td>89903</td>\n",
       "      <td>Wellington City, New Zealand</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>airline pilots offering to stock supermarket s...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41153</th>\n",
       "      <td>44952</td>\n",
       "      <td>89904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>response to complaint not provided citing covi...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41154</th>\n",
       "      <td>44953</td>\n",
       "      <td>89905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>you know it  s getting tough when  kameronwild...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41155</th>\n",
       "      <td>44954</td>\n",
       "      <td>89906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>is it wrong that the smell of hand sanitizer i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41156</th>\n",
       "      <td>44955</td>\n",
       "      <td>89907</td>\n",
       "      <td>i love you so much || he/him</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>tartiicat well new used rift s are going for ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41157 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       UserName  ScreenName                      Location     TweetAt  \\\n",
       "0          3799       48751                        London  16-03-2020   \n",
       "1          3800       48752                            UK  16-03-2020   \n",
       "2          3801       48753                     Vagabonds  16-03-2020   \n",
       "3          3802       48754                           NaN  16-03-2020   \n",
       "4          3803       48755                           NaN  16-03-2020   \n",
       "...         ...         ...                           ...         ...   \n",
       "41152     44951       89903  Wellington City, New Zealand  14-04-2020   \n",
       "41153     44952       89904                           NaN  14-04-2020   \n",
       "41154     44953       89905                           NaN  14-04-2020   \n",
       "41155     44954       89906                           NaN  14-04-2020   \n",
       "41156     44955       89907  i love you so much || he/him  14-04-2020   \n",
       "\n",
       "                                           OriginalTweet           Sentiment  \n",
       "0       menyrbie  phil_gahan  chrisitv https   t co i...             Neutral  \n",
       "1      advice talk to your neighbours family to excha...            Positive  \n",
       "2      coronavirus australia  woolworths to give elde...            Positive  \n",
       "3      my food stock is not the only one which is emp...            Positive  \n",
       "4      me  ready to go at supermarket during the  cov...  Extremely Negative  \n",
       "...                                                  ...                 ...  \n",
       "41152  airline pilots offering to stock supermarket s...             Neutral  \n",
       "41153  response to complaint not provided citing covi...  Extremely Negative  \n",
       "41154  you know it  s getting tough when  kameronwild...            Positive  \n",
       "41155  is it wrong that the smell of hand sanitizer i...             Neutral  \n",
       "41156   tartiicat well new used rift s are going for ...            Negative  \n",
       "\n",
       "[41157 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_non_alphabetic_chars(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "857882a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the dataframe df with tweets after removing characters which are not alphabetic or whitespaces.\n",
    "def remove_multiple_consecutive_whitespaces(df):\n",
    "    #df['OriginalTweet'] = df['OriginalTweet'].replace('\\s+', ' ', regex=True)\n",
    "    df['OriginalTweet'] = df['OriginalTweet'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95fede6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>menyrbie  phil_gahan  chrisitv https   t co if...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>coronavirus australia  woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>my food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>me  ready to go at supermarket during the  cov...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41152</th>\n",
       "      <td>44951</td>\n",
       "      <td>89903</td>\n",
       "      <td>Wellington City, New Zealand</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>airline pilots offering to stock supermarket s...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41153</th>\n",
       "      <td>44952</td>\n",
       "      <td>89904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>response to complaint not provided citing covi...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41154</th>\n",
       "      <td>44953</td>\n",
       "      <td>89905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>you know it  s getting tough when  kameronwild...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41155</th>\n",
       "      <td>44954</td>\n",
       "      <td>89906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>is it wrong that the smell of hand sanitizer i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41156</th>\n",
       "      <td>44955</td>\n",
       "      <td>89907</td>\n",
       "      <td>i love you so much || he/him</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>tartiicat well new used rift s are going for  ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41157 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       UserName  ScreenName                      Location     TweetAt  \\\n",
       "0          3799       48751                        London  16-03-2020   \n",
       "1          3800       48752                            UK  16-03-2020   \n",
       "2          3801       48753                     Vagabonds  16-03-2020   \n",
       "3          3802       48754                           NaN  16-03-2020   \n",
       "4          3803       48755                           NaN  16-03-2020   \n",
       "...         ...         ...                           ...         ...   \n",
       "41152     44951       89903  Wellington City, New Zealand  14-04-2020   \n",
       "41153     44952       89904                           NaN  14-04-2020   \n",
       "41154     44953       89905                           NaN  14-04-2020   \n",
       "41155     44954       89906                           NaN  14-04-2020   \n",
       "41156     44955       89907  i love you so much || he/him  14-04-2020   \n",
       "\n",
       "                                           OriginalTweet           Sentiment  \n",
       "0      menyrbie  phil_gahan  chrisitv https   t co if...             Neutral  \n",
       "1      advice talk to your neighbours family to excha...            Positive  \n",
       "2      coronavirus australia  woolworths to give elde...            Positive  \n",
       "3      my food stock is not the only one which is emp...            Positive  \n",
       "4      me  ready to go at supermarket during the  cov...  Extremely Negative  \n",
       "...                                                  ...                 ...  \n",
       "41152  airline pilots offering to stock supermarket s...             Neutral  \n",
       "41153  response to complaint not provided citing covi...  Extremely Negative  \n",
       "41154  you know it  s getting tough when  kameronwild...            Positive  \n",
       "41155  is it wrong that the smell of hand sanitizer i...             Neutral  \n",
       "41156  tartiicat well new used rift s are going for  ...            Negative  \n",
       "\n",
       "[41157 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_multiple_consecutive_whitespaces(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be88d288",
   "metadata": {},
   "source": [
    "## [14 points] \n",
    "\n",
    "### Tokenize the tweets (i.e. convert each into a list of words), count the total number of all words (including repetitions), the number of all distinct words and the 10 most frequent words in the corpus. Remove stop words, words with ≤ 2 characters, and reduce each word to its stem. You are now able to recompute the 10 most frequent words in the modified corpus. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cac4e1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a dataframe where each tweet is one string with words separated by single whitespaces,\n",
    "# tokenize every tweet by converting it into a list of words (strings).\n",
    "def tokenize(df):\n",
    "    df['OriginalTweet'] = df['OriginalTweet'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b5e277a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>[menyrbie, phil_gahan, chrisitv, https, t, co,...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>[advice, talk, to, your, neighbours, family, t...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>[coronavirus, australia, woolworths, to, give,...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>[my, food, stock, is, not, the, only, one, whi...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>[me, ready, to, go, at, supermarket, during, t...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41152</th>\n",
       "      <td>44951</td>\n",
       "      <td>89903</td>\n",
       "      <td>Wellington City, New Zealand</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>[airline, pilots, offering, to, stock, superma...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41153</th>\n",
       "      <td>44952</td>\n",
       "      <td>89904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>[response, to, complaint, not, provided, citin...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41154</th>\n",
       "      <td>44953</td>\n",
       "      <td>89905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>[you, know, it, s, getting, tough, when, kamer...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41155</th>\n",
       "      <td>44954</td>\n",
       "      <td>89906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>[is, it, wrong, that, the, smell, of, hand, sa...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41156</th>\n",
       "      <td>44955</td>\n",
       "      <td>89907</td>\n",
       "      <td>i love you so much || he/him</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>[tartiicat, well, new, used, rift, s, are, goi...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41157 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       UserName  ScreenName                      Location     TweetAt  \\\n",
       "0          3799       48751                        London  16-03-2020   \n",
       "1          3800       48752                            UK  16-03-2020   \n",
       "2          3801       48753                     Vagabonds  16-03-2020   \n",
       "3          3802       48754                           NaN  16-03-2020   \n",
       "4          3803       48755                           NaN  16-03-2020   \n",
       "...         ...         ...                           ...         ...   \n",
       "41152     44951       89903  Wellington City, New Zealand  14-04-2020   \n",
       "41153     44952       89904                           NaN  14-04-2020   \n",
       "41154     44953       89905                           NaN  14-04-2020   \n",
       "41155     44954       89906                           NaN  14-04-2020   \n",
       "41156     44955       89907  i love you so much || he/him  14-04-2020   \n",
       "\n",
       "                                           OriginalTweet           Sentiment  \n",
       "0      [menyrbie, phil_gahan, chrisitv, https, t, co,...             Neutral  \n",
       "1      [advice, talk, to, your, neighbours, family, t...            Positive  \n",
       "2      [coronavirus, australia, woolworths, to, give,...            Positive  \n",
       "3      [my, food, stock, is, not, the, only, one, whi...            Positive  \n",
       "4      [me, ready, to, go, at, supermarket, during, t...  Extremely Negative  \n",
       "...                                                  ...                 ...  \n",
       "41152  [airline, pilots, offering, to, stock, superma...             Neutral  \n",
       "41153  [response, to, complaint, not, provided, citin...  Extremely Negative  \n",
       "41154  [you, know, it, s, getting, tough, when, kamer...            Positive  \n",
       "41155  [is, it, wrong, that, the, smell, of, hand, sa...             Neutral  \n",
       "41156  [tartiicat, well, new, used, rift, s, are, goi...            Negative  \n",
       "\n",
       "[41157 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(df)\n",
    "tdf = df.copy()\n",
    "tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b391134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1349274"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given dataframe tdf with the tweets tokenized, \n",
    "# return the number of words in all tweets including repetitions.\n",
    "\n",
    "def count_words_with_repetitions(tdf): \n",
    "    all_words = 0\n",
    "    all_words = all_words + tdf['OriginalTweet'].apply(lambda x: len(x))\n",
    "    return all_words.sum()\n",
    "\n",
    "count_words_with_repetitions(tdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a57ce89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80544"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given dataframe tdf with the tweets tokenized, \n",
    "# return the number of distinct words in all tweets.\n",
    "def count_words_without_repetitions(tdf):\n",
    "    all_words = tdf.explode('OriginalTweet')\n",
    "    all_words_list = list(all_words['OriginalTweet'])\n",
    "    all_words_no_rep = set(all_words_list)\n",
    "    return len(all_words_no_rep)\n",
    "\n",
    "count_words_without_repetitions(tdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8626dc2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'to', 't', 'co', 'and', 'https', 'of', 'a', 'covid', 'in']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given dataframe tdf with the tweets tokenized, \n",
    "# return a list with the k distinct words that are most frequent in the tweets.\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def frequent_words(tdf,k):\n",
    "    all_words = tdf.explode('OriginalTweet')\n",
    "    all_words_list = list(all_words['OriginalTweet'])\n",
    "    freq_words = Counter(all_words_list).most_common(k)\n",
    "    output = [c[0] for c in freq_words]\n",
    "    return output\n",
    "    \n",
    "frequent_words(tdf,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8b1f6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given dataframe tdf with the tweets tokenized, remove stop words and words with <=2 characters from each tweet.\n",
    "# The function should download the list of stop words via:\n",
    "# https://raw.githubusercontent.com/fozziethebeat/S-Space/master/data/english-stop-words-large.txt\n",
    "\n",
    "import csv\n",
    "\n",
    "def remove_stop_words(tdf):\n",
    "    stop_words = pd.read_csv('https://raw.githubusercontent.com/fozziethebeat/S-Space/master/data/english-stop-words-large.txt',\n",
    "                     sep = \" \", header = None, names = ['list'], quoting = csv.QUOTE_NONE, encoding = 'utf-8')\n",
    "    \n",
    "    for index,row in tdf['OriginalTweet'].items():\n",
    "        tdf.at[index,'OriginalTweet'] = [x for x in row if (x not in stop_words) and len(x) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e15b423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['menyrbie',\n",
       " 'phil_gahan',\n",
       " 'chrisitv',\n",
       " 'https',\n",
       " 't',\n",
       " 'co',\n",
       " 'ifz',\n",
       " 'fan',\n",
       " 'pa',\n",
       " 'and',\n",
       " 'https',\n",
       " 't',\n",
       " 'co',\n",
       " 'xx',\n",
       " 'ghgfzcc',\n",
       " 'and',\n",
       " 'https',\n",
       " 't',\n",
       " 'co',\n",
       " 'i',\n",
       " 'nlzdxno']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove_stop_words(tdf)\n",
    "tdf.at[0,'OriginalTweet'] # where index can be any number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18f13776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given dataframe tdf with the tweets tokenized, reduce each word in every tweet to its stem.\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "# Use English stemmer.\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stemming(tdf):\n",
    "    tdf['OriginalTweet'] = tdf['OriginalTweet'].apply(lambda x: [stemmer.stem(y) for y in x]) # Stem every word.## [13 points]\n",
    "\n",
    "### This task can be done individually from the previous three. Store the coronavirus tweets.py corpus in a numpy array and produce a sparse representation of the termdocument matrix with a CountVectorizer. \n",
    "\n",
    "### Next, produce a Multinomial Naive Bayes classifier using the provided data set. What is the classifier’s training accuracy? A CountVectorizer allows limiting the range of frequencies and number of words included in the term-document matrix. Appropriately tune these parameters to achieve the highest classification accuracy you can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de5b196e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>[menyrbi, phil_gahan, chrisitv, http, t, co, i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>[advic, talk, to, your, neighbour, famili, to,...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>[coronaviru, australia, woolworth, to, give, e...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>[my, food, stock, is, not, the, onli, one, whi...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>[me, readi, to, go, at, supermarket, dure, the...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41152</th>\n",
       "      <td>44951</td>\n",
       "      <td>89903</td>\n",
       "      <td>Wellington City, New Zealand</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>[airlin, pilot, offer, to, stock, supermarket,...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41153</th>\n",
       "      <td>44952</td>\n",
       "      <td>89904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>[respons, to, complaint, not, provid, cite, co...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41154</th>\n",
       "      <td>44953</td>\n",
       "      <td>89905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>[you, know, it, s, get, tough, when, kameronwi...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41155</th>\n",
       "      <td>44954</td>\n",
       "      <td>89906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>[is, it, wrong, that, the, smell, of, hand, sa...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41156</th>\n",
       "      <td>44955</td>\n",
       "      <td>89907</td>\n",
       "      <td>i love you so much || he/him</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>[tartiicat, well, new, use, rift, s, are, go, ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41157 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       UserName  ScreenName                      Location     TweetAt  \\\n",
       "0          3799       48751                        London  16-03-2020   \n",
       "1          3800       48752                            UK  16-03-2020   \n",
       "2          3801       48753                     Vagabonds  16-03-2020   \n",
       "3          3802       48754                           NaN  16-03-2020   \n",
       "4          3803       48755                           NaN  16-03-2020   \n",
       "...         ...         ...                           ...         ...   \n",
       "41152     44951       89903  Wellington City, New Zealand  14-04-2020   \n",
       "41153     44952       89904                           NaN  14-04-2020   \n",
       "41154     44953       89905                           NaN  14-04-2020   \n",
       "41155     44954       89906                           NaN  14-04-2020   \n",
       "41156     44955       89907  i love you so much || he/him  14-04-2020   \n",
       "\n",
       "                                           OriginalTweet           Sentiment  \n",
       "0      [menyrbi, phil_gahan, chrisitv, http, t, co, i...             Neutral  \n",
       "1      [advic, talk, to, your, neighbour, famili, to,...            Positive  \n",
       "2      [coronaviru, australia, woolworth, to, give, e...            Positive  \n",
       "3      [my, food, stock, is, not, the, onli, one, whi...            Positive  \n",
       "4      [me, readi, to, go, at, supermarket, dure, the...  Extremely Negative  \n",
       "...                                                  ...                 ...  \n",
       "41152  [airlin, pilot, offer, to, stock, supermarket,...             Neutral  \n",
       "41153  [respons, to, complaint, not, provid, cite, co...  Extremely Negative  \n",
       "41154  [you, know, it, s, get, tough, when, kameronwi...            Positive  \n",
       "41155  [is, it, wrong, that, the, smell, of, hand, sa...             Neutral  \n",
       "41156  [tartiicat, well, new, use, rift, s, are, go, ...            Negative  \n",
       "\n",
       "[41157 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming(tdf)\n",
    "tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17a465c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['menyrbi',\n",
       " 'phil_gahan',\n",
       " 'chrisitv',\n",
       " 'http',\n",
       " 't',\n",
       " 'co',\n",
       " 'ifz',\n",
       " 'fan',\n",
       " 'pa',\n",
       " 'and',\n",
       " 'http',\n",
       " 't',\n",
       " 'co',\n",
       " 'xx',\n",
       " 'ghgfzcc',\n",
       " 'and',\n",
       " 'http',\n",
       " 't',\n",
       " 'co',\n",
       " 'i',\n",
       " 'nlzdxno']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf.at[0,'OriginalTweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5582925a",
   "metadata": {},
   "source": [
    "## [13 points]\n",
    "\n",
    "### This task can be done individually from the previous three. Store the coronavirus tweets.py corpus in a numpy array and produce a sparse representation of the termdocument matrix with a CountVectorizer. \n",
    "\n",
    "### Next, produce a Multinomial Naive Bayes classifier using the provided data set. What is the classifier’s training accuracy? A CountVectorizer allows limiting the range of frequencies and number of words included in the term-document matrix. Appropriately tune these parameters to achieve the highest classification accuracy you can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ab0fe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(df) * 0.8)\n",
    "test_size = len(df) - train_size\n",
    "#train, test = df['OriginalTweet'].values.iloc[0:train_size], df['OriginalTweet'].values.iloc[train_size:len(df['OriginalTweet'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f41052a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'> - type of the term document matrix\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2c/q0jzg_j92xjbxq26p0b0hmbh0000gn/T/ipykernel_99579/2569787238.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_csv_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'coronavirus_tweets.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mmnb_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/2c/q0jzg_j92xjbxq26p0b0hmbh0000gn/T/ipykernel_99579/2569787238.py\u001b[0m in \u001b[0;36mmnb_predict\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_train_dtm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'- type of the term document matrix'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msimple_train_dtm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 's' is not defined"
     ]
    }
   ],
   "source": [
    "# Given a pandas dataframe df with the original coronavirus_tweets.csv data set,\n",
    "# build a Multinomial Naive Bayes classifier. \n",
    "# Return predicted sentiments (e.g. 'Neutral', 'Positive') for the training set\n",
    "# as a 1d array (numpy.ndarray). \n",
    "\n",
    "# 1. import and instantiate CountVectorizer (with the default parameters)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "    \n",
    "def mnb_predict(df):\n",
    "    # 2. instantiate CountVectorizer (vectorizer)\n",
    "    vect = CountVectorizer()\n",
    "    # 3. fit\n",
    "    # learn the 'vocabulary' of the training data (occurs in-place)\n",
    "    simple_train = df['OriginalTweet'].values\n",
    "    vect.fit(simple_train)\n",
    "    #print(vect.get_feature_names())\n",
    "    # 4. transform training data into a 'term document matrix'\n",
    "    simple_train_dtm = vect.transform(simple_train)\n",
    "    print(type(simple_train_dtm), '- type of the term document matrix')\n",
    "    \n",
    "    s\n",
    "    return simple_train_dtm\n",
    "\n",
    "df = read_csv_3('coronavirus_tweets.csv')\n",
    "mnb_predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7d5b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a 1d array (numpy.ndarray) y_pred with predicted labels (e.g. 'Neutral', 'Positive') \n",
    "# by a classifier and another 1d array y_true with the true labels, \n",
    "# return the classification accuracy rounded in the 3rd decimal digit.\n",
    "def mnb_accuracy(y_pred,y_true):\n",
    "\tpass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
